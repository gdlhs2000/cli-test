{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gdlhs2000/cli-test/blob/main/%EC%8B%A4%EC%8A%B51.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 디렉토리 이동\n",
        "cd ~   #/home/Ubuntu\n",
        "\n",
        "## Docker container 실행\n",
        "sudo docker run --gpus all --privileged --ipc=host --ulimit memlock=-1 --rm -v $(pwd)/data:/workspace/data -p 8888:8888 ashgold2/pytorch:24.01-py3 jupyter notebook --port=8888 --ip=0.0.0.0 --allow-root --no-browser /workspace/data\n"
      ],
      "metadata": {
        "id": "oVP4Zke-0Ai_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xutyxmWKzjLB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"TinyLlama-1.1B-Chat-v1.0\", device_map=\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate answer as long as possible.\",\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\": \"Write a novel in sci-fi genre. you should answer with more than 1000 words.\"},\n",
        "]\n",
        "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n"
      ],
      "metadata": {
        "id": "tWUPQcVBzuTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "outputs = pipe(prompt, max_new_tokens=500, do_sample=True, temperature=0.3, top_k=10, top_p=0.95, return_full_text=True)\n",
        "end = time.time()\n",
        "print(outputs[0][\"generated_text\"])\n",
        "print(f\"elapsed time:{end-start} seconds\")\n"
      ],
      "metadata": {
        "id": "3SYZ29tCzurm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}